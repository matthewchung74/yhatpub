{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson10_generation",
      "provenance": [],
      "authorship_tag": "ABX9TyN44UfvUghnPrm8MzHSdcju",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yhatpub/yhatpub/blob/dev/notebooks/fastai/lesson10_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brjCYxrw34vF"
      },
      "source": [
        "# Fastai Lesson 10 on YHat.pub\n",
        "\n",
        "This notebook picks up from [Fastai Fastbook 10 Text Generation](https://github.com/yhatpub/blogs/blob/main/10_nlp.ipynb) to [YHat.pub](https://yhat.pub)\n",
        "\n",
        "To save your model, you'll need to export the pickled model after training, taking note of the export file size. Here is an example below\n",
        "```\n",
        "learn.export('/content/export.pkl')\n",
        "!ls -l /content/export.pkl\n",
        "from google.colab import files\n",
        "files.download('/content/export.pkl')\n",
        "```\n",
        "Then upload it for public accessibility. Here is an example using [Google Drive](https://github.com/yhatpub/yhatpub#step-2-upload-your-model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0poAZ683-11"
      },
      "source": [
        "### Installs\n",
        "The following cell installs pytorch, fastai and yhat_params, which is used to decorate your `predict` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEou7Z444C0K",
        "outputId": "96c49ee6-fd09-4765-97c6-262ff5ab01cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# !pip install -q --upgrade --no-cache-dir torch\n",
        "!pip install -q --upgrade --no-cache-dir fastai\n",
        "\n",
        "# older version required to work with fastai\n",
        "!pip install -q spacy==2.2.4\n",
        "!pip install -q --no-cache-dir git+https://github.com/yhatpub/yhat_params.git@main"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 189 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 29.9 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 131 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 22.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 51.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.1 MB 46.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 55.3 MB/s \n",
            "\u001b[?25h  Building wheel for yhat-params (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6a2q7PG2Fus"
      },
      "source": [
        "Add the following since matplotlib needs to know where to write it's temp files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ5y9iJW2NL7"
      },
      "source": [
        "import os\n",
        "import tempfile\n",
        "os.environ[\"MPLCONFIGDIR\"] = tempfile.gettempdir()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXbb-xMt4F10"
      },
      "source": [
        "### Imports\n",
        "**Warning** don't place `pip installs` and `imports` in the same cell. The imports might not work correctly if done that way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdBGoC__4GXd"
      },
      "source": [
        "from fastai.text.all import *\n",
        "from yhat_params.yhat_tools import FieldType, inference_predict"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8T-fAxr4HCO"
      },
      "source": [
        "### Download Model\n",
        "Google drive does not allow direct downloads for files over 100MB, so you'll need to follow the snippet below to get the download url."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmoHbybY4JTy",
        "outputId": "400e5ccb-9f57-4ebb-9408-390b00aa0f07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#cleanup from previous download\n",
        "!rm -f uc*\n",
        "\n",
        "#file copied from google drive\n",
        "google_drive_url = \"https://drive.google.com/file/d/10UWnRYV0H9h7T6_CJCashvfh31k9oiLK/view?usp=sharing\"\n",
        "import os\n",
        "os.environ['GOOGLE_FILE_ID'] = google_drive_url.split('/')[5]\n",
        "os.environ['GDRIVE_URL'] = f'https://docs.google.com/uc?export=download&id={os.environ[\"GOOGLE_FILE_ID\"]}'\n",
        "!echo \"This is the Google drive download url $GDRIVE_URL\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the Google drive download url https://docs.google.com/uc?export=download&id=10UWnRYV0H9h7T6_CJCashvfh31k9oiLK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5zE1GY04J10"
      },
      "source": [
        "`wget` it from google drive. This script places the model in a `model` folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0z3ZMaU4MQ8"
      },
      "source": [
        "!wget -q --no-check-certificate $GDRIVE_URL -r -A 'uc*' -e robots=off -nd\n",
        "!mkdir -p models\n",
        "!mv $(ls -S uc* | head -1) ./models/export.pkl"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJO6xPA14OJY"
      },
      "source": [
        "verify the model exists and double check the file size. **Warning** YHat is pretty finicky about where you place your models. Make sure you create a `model` directory and download your model(s) there  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGMgLBw94OqR",
        "outputId": "f7d7f577-545f-4cb6-baa1-f8d7e2438036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls -l models"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 239228\n",
            "-rw-r--r-- 1 root root 244964427 Nov  1 18:53 export.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPKXMFUA4PI8"
      },
      "source": [
        "### Load your learner\n",
        "The following is the equivalent of torch `torch.load` or ts `model.load_weights`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_JXmfFg4ROO"
      },
      "source": [
        "learn_inf = load_learner('models/export.pkl')\n",
        "learn_inf.model.eval();"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ8WiWaf4Sz2"
      },
      "source": [
        "And write your predict function. Note, you will need to decorate your function with <a href=\"https://github.com/yhatpub/yhat_params\">inference_predict</a> which takes 2 parameters, a `dic` for input and output.\n",
        "\n",
        "**Info** These parameters are how YHat.pub maps your predict functions input/output of the web interface. The `dic` key is how you access the variable and the value is it's type. You can use autocomplete to see all the input/output types and more documentation on `inference_predict` is available at the link. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm0ji7TG4TLD"
      },
      "source": [
        "input = {\"text\": FieldType.Text}\n",
        "output = {\"text\": FieldType.Text}\n",
        "N_WORDS = 20\n",
        "N_SENTENCES = 1\n",
        "\n",
        "@inference_predict(input=input, output=output)\n",
        "def predict(params):\n",
        "    preds = [learn_inf.predict(params[\"text\"], N_WORDS, temperature=0.75) \n",
        "         for _ in range(N_SENTENCES)]\n",
        "    output = \"\\n\".join(preds)\n",
        "    return {\"text\":output}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tjb1Hac4V1L"
      },
      "source": [
        "### Test\n",
        "First, import `in_colab` since you only want to run this test in colab. YHat will use this colab in a callable API, so you don't want your test to run every time `predict` is called. Next, import `inference_test` which is a function to make sure your `predict` will run with YHat.\n",
        "\n",
        "Now, inside a `in_colab` boolean, first get whatever test data you'll need, in this case, an image. Then you'll call your predict function, wrapped inside  `inference_test`, passing in the same params you defined above. If something is missing, you should see an informative error. Otherwise, you'll see something like\n",
        "`Please take a look and verify the results`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhNKiYae4WL1",
        "outputId": "def0a3fb-0ee6-4bff-d070-e0a464785f01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from yhat_params.yhat_tools import in_colab, inference_test\n",
        "\n",
        "if in_colab():\n",
        "    inference_test(predict_func=predict, params={'text': \"I liked this movie because\"})"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote results to result.json duration: 3.425878 seconds\n",
            "Please take a look and verify the results\n",
            "{\n",
            "    \"text\": \"i liked this movie because it was filmed in Columbia , and i do n't think i have seen any Spielberg pictures in\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr0wnsJc4XJA"
      },
      "source": [
        "### That's it\n",
        "\n",
        "If you run into errors, feel free to hop into Discord.\n",
        "\n",
        "Otherwise, you'll now want to clear your outputs and save a public repo on Github"
      ]
    }
  ]
}