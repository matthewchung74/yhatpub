{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6CHmYH9hRUxv+PFoQiYrF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yhatpub/yhatpub/blob/notebook/notebooks/fastai/lesson2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jefeyf4rNvw"
      },
      "source": [
        "# Fastai Lesson 2 on YHat.pub\n",
        "\n",
        "This notebook picks up from [Fastai Fastbook 02_production](https://github.com/fastai/fastbook/blob/master/02_production.ipynb) publishing your bear classifier to [YHat.pub](https://yhat.pub)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2vRnqmgUr6i"
      },
      "source": [
        "### Installs\n",
        "The following cell installs pytorch, fastai and yhat_params, which is used to decorate your `predict` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4AzcNoIm4GP"
      },
      "source": [
        "!pip install -q --upgrade --no-cache-dir torch torchvision torchaudio\n",
        "!pip install -q --upgrade --no-cache-dir fastai\n",
        "\n",
        "!pip install -q --no-cache-dir git+https://github.com/yhatpub/yhat_params.git@main"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wktM7u5GVEN5"
      },
      "source": [
        "### Imports\n",
        "**Warning** don't place `pip installs` and `imports` in the same cell. The imports might not work correctly if done that way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvT09y4AtYUU"
      },
      "source": [
        "from fastai.vision.all import *\n",
        "from yhat_params.yhat_tools import FieldType, inference_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eooRH7vkaGNR"
      },
      "source": [
        "### Download Model\n",
        "Google drive does not allow direct downloads for files over 100MB, so you'll need to follow the snippet below to get the download url."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAG2YajPaoaN"
      },
      "source": [
        "#file copied from google drive\n",
        "google_drive_url = \"https://drive.google.com/file/d/1ZbiJe5iM19b2dteN_Nun1cWFJW6o8Lx3/view?usp=sharing\"\n",
        "import os\n",
        "os.environ['GOOGLE_FILE_ID'] = google_drive_url.split('/')[5]\n",
        "os.environ['GDRIVE_URL'] = f'https://docs.google.com/uc?export=download&id={os.environ[\"GOOGLE_FILE_ID\"]}'\n",
        "!echo \"This is the Google drive download url $GDRIVE_URL\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMJwEJWkhRN-"
      },
      "source": [
        "`wget` it from google drive. This script places the model in a `model` folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SOvzRzWg_eH"
      },
      "source": [
        "!wget -q --no-check-certificate $GDRIVE_URL -r -A 'uc*' -e robots=off -nd\n",
        "!mkdir -p model\n",
        "!mv $(ls -S uc* | head -1) ./model/export.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-96f4IChWgP"
      },
      "source": [
        "verify the model exists. **Warning** YHat is pretty finicky about where you place your models. Make sure you create a `model` directory and download your model(s) there  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPndBYMqfaER"
      },
      "source": [
        "!ls -l ./model/export.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WjzwI_Lh2-L"
      },
      "source": [
        "### Load your learner\n",
        "The following is the equivalent of torch `torch.load` or ts `model.load_weights`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F48Vxtl9m9bZ"
      },
      "source": [
        "learn_inf = load_learner('./model/export.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQKFj_s5ml90"
      },
      "source": [
        "And write your predict function. Note, you will need to decorate your function with <a href=\"https://github.com/yhatpub/yhat_params\">inference_predict</a> which takes 2 parameters, a `dic` for input and output.\n",
        "\n",
        "**Info** These parameters are how YHat.pub maps your predict functions input/output of the web interface. The `dic` key is how you access the variable and the value is it's type. You can use autocomplete to see all the input/output types and more documentation on `inference_predict` is available at the link. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6tBxYZRm-fT"
      },
      "source": [
        "input = {\"image\": FieldType.PIL}\n",
        "output = {\"text\": FieldType.Text}\n",
        "\n",
        "@inference_predict(input=input, output=output)\n",
        "def predict(params):\n",
        "    img = PILImage.create(np.array(params[\"image\"].convert(\"RGB\")))\n",
        "    pred,pred_idx,probs = learn_inf.predict(img)\n",
        "    return {\"text\":  f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNEnu7Olm7Ri"
      },
      "source": [
        "### Test\n",
        "First, import `in_colab` since you only want to run this test in colab. YHat will use this colab in a callable API, so you don't want your test to run every time `predict` is called. Next, import `inference_test` which is a function to make sure your `predict` will run with YHat.\n",
        "\n",
        "Now, inside a `in_colab` boolean, first get whatever test data you'll need, in this case, an image. Then you'll call your predict function, wrapped inside  `inference_test`, passing in the same params you defined above. If something is missing, you should see an informative error. Otherwise, you'll see something like\n",
        "`Please take a look and verify the results`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvuNezKWm_dY"
      },
      "source": [
        "from yhat_params.yhat_tools import in_colab, inference_test\n",
        "\n",
        "if in_colab():\n",
        "    import urllib.request\n",
        "    from PIL import Image\n",
        "    urllib.request.urlretrieve(\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/GrizzlyBearJeanBeaufort.jpg/220px-GrizzlyBearJeanBeaufort.jpg\", \"input_image.jpg\")\n",
        "    img = Image.open(\"input_image.jpg\")\n",
        "    inference_test(predict_func=predict, params={'image': img})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN9GXkO64Hp9"
      },
      "source": [
        "### That's it\n",
        "\n",
        "If you run into errors, feel free to hop into Discord.\n",
        "\n",
        "Otherwise, you'll now want to clear your outputs and save a public repo on Github"
      ]
    }
  ]
}