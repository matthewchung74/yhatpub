{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson6_regression",
      "provenance": [],
      "authorship_tag": "ABX9TyNGLg0qMfUBbIxhceo+SEWT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yhatpub/yhatpub/blob/main/notebooks/fastai/lesson6_pose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brjCYxrw34vF"
      },
      "source": [
        "# Fastai Lesson Regression on YHat.pub\n",
        "\n",
        "This notebook picks up from [Fastai Fastbook 6 Regression](https://github.com/fastai/fastbook/blob/master/06_multicat.ipynb) to [YHat.pub](https://yhat.pub)\n",
        "\n",
        "To save your model, you'll need to save just the weights and balances of the model, the `pth` file for your learner. A really nice and easy to follow tutorial on `pth` files is here [inference-with-fastai](https://benjaminwarner.dev/2021/10/01/inference-with-fastai)\n",
        "\n",
        "This is because `load_learner` from lesson 6 relies on the serialized `get_ctr` method, which when unserialzied, need to be on the `__main__` module. If that doesn't make sense, don't worry about it. Just follow the steps below and you'll be fine.\n",
        "\n",
        "On your lesson 6 notebook, after fine tuning your learner, do the following to save and download your `pth` file\n",
        "```\n",
        "learn.save('lesson_6_pose', with_opt=False)\n",
        "from google.colab import files\n",
        "files.download('models/lesson_6_pose.pth') \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0poAZ683-11"
      },
      "source": [
        "### Installs\n",
        "The following cell installs pytorch, fastai and yhat_params, which is used to decorate your `predict` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEou7Z444C0K"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade --no-cache-dir fastai\n",
        "!pip install -q --no-cache-dir git+https://github.com/yhatpub/yhat_params.git@main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3gDSW3I67Ki"
      },
      "source": [
        "Add the following since matplotlib needs to know where to write it's temp files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coiXH5Jn68M1"
      },
      "source": [
        "import os\n",
        "import tempfile\n",
        "os.environ[\"MPLCONFIGDIR\"] = tempfile.gettempdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXbb-xMt4F10"
      },
      "source": [
        "### Imports\n",
        "**Warning** don't place `pip installs` and `imports` in the same cell. The imports might not work correctly if done that way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdBGoC__4GXd"
      },
      "outputs": [],
      "source": [
        "from fastai.vision.all import *\n",
        "from yhat_params.yhat_tools import FieldType, inference_predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8T-fAxr4HCO"
      },
      "source": [
        "### Download Model\n",
        "Google drive does not allow direct downloads for files over 100MB, so you'll need to follow the snippet below to get the download url."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmoHbybY4JTy"
      },
      "outputs": [],
      "source": [
        "#cleanup from previous download\n",
        "!rm uc*\n",
        "\n",
        "#file copied from google drive\n",
        "google_drive_url = \"https://drive.google.com/file/d/10tkEH4-e9mEsxlZlfA1Ta-ILxwtzzHFO/view?usp=sharing\"\n",
        "import os\n",
        "os.environ['GOOGLE_FILE_ID'] = google_drive_url.split('/')[5]\n",
        "os.environ['GDRIVE_URL'] = f'https://docs.google.com/uc?export=download&id={os.environ[\"GOOGLE_FILE_ID\"]}'\n",
        "!echo \"This is the Google drive download url $GDRIVE_URL\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5zE1GY04J10"
      },
      "source": [
        "`wget` it from google drive. This script places the model in a `model` folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0z3ZMaU4MQ8"
      },
      "outputs": [],
      "source": [
        "!wget -q --no-check-certificate $GDRIVE_URL -r -A 'uc*' -e robots=off -nd\n",
        "!mkdir -p models\n",
        "!mv $(ls -S uc* | head -1) ./models/export.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJO6xPA14OJY"
      },
      "source": [
        "verify the model exists. **Warning** YHat is pretty finicky about where you place your models. Make sure you create a `model` directory and download your model(s) there  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGMgLBw94OqR"
      },
      "outputs": [],
      "source": [
        "!ls -l models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXBm0yLMb9qc"
      },
      "source": [
        "### Recreate dataloader and learner\n",
        "\n",
        "Let's start by creating a dummy image for regression. This is going to be used for our dataloader. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsMgjcgZcHKN"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "\n",
        "if not os.path.exists('data'):\n",
        "    os.mkdir('data')\n",
        "    img = Image.new('RGB', (1, 1))\n",
        "    img.save('data/dummyimage.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8399pZycUmr"
      },
      "source": [
        "And now, we can make a lightweight `DataBlock`, passing in the single image and dummy regression value. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e26ovyKKcYda"
      },
      "outputs": [],
      "source": [
        "dblock = DataBlock(\n",
        "    blocks=(ImageBlock, PointBlock),\n",
        "    get_x=ColReader('image'), \n",
        "    get_y=ColReader('point'),    \n",
        "    batch_tfms=[*aug_transforms(size=(240,320)), \n",
        "                Normalize.from_stats(*imagenet_stats)])\n",
        "\n",
        "df = pd.DataFrame(\n",
        "     {\n",
        "        'image': [\n",
        "                  \"data/dummyimage.jpg\", \n",
        "                  ], \n",
        "        'point': [\n",
        "                  np.array([1,1]), \n",
        "                  ], \n",
        "     },\n",
        "    )\n",
        "dls = dblock.dataloaders(df, bs=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPKXMFUA4PI8"
      },
      "source": [
        "### Load your learner\n",
        "The following is the equivalent of torch `torch.load` or ts `model.load_weights`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_JXmfFg4ROO"
      },
      "outputs": [],
      "source": [
        "learn_inf = cnn_learner(dls, resnet18, y_range=(-1,1), pretrained=False)\n",
        "learn_inf.load('export')\n",
        "learn_inf.model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ8WiWaf4Sz2"
      },
      "source": [
        "And write your predict function. Note, you will need to decorate your function with <a href=\"https://github.com/yhatpub/yhat_params\">inference_predict</a> which takes 2 parameters, a `dic` for input and output.\n",
        "\n",
        "**Info** These parameters are how YHat.pub maps your predict functions input/output of the web interface. The `dic` key is how you access the variable and the value is it's type. You can use autocomplete to see all the input/output types and more documentation on `inference_predict` is available at the link. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rm0ji7TG4TLD"
      },
      "outputs": [],
      "source": [
        "input = {\"image\": FieldType.PIL}\n",
        "output = {\"text\": FieldType.Text, \"image\": FieldType.PIL}\n",
        "\n",
        "@inference_predict(input=input, output=output)\n",
        "def predict(params):\n",
        "    img = PILImage.create(np.array(params[\"image\"].convert(\"RGB\")))\n",
        "    result = learn_inf.predict(img)\n",
        "    x = float(result[0][0][0])\n",
        "    y = float(result[0][0][1])\n",
        "\n",
        "    input_image = params[\"image\"]\n",
        "    input_image = input_image.resize((320, 240))\n",
        "    draw = ImageDraw.Draw(input_image)\n",
        "    radius = 2\n",
        "    draw.ellipse((x-radius, y-radius, x+radius, y+radius), fill=(0, 255, 0), outline=(0, 0, 0))\n",
        "\n",
        "    return {\"text\": f\"Positions ({x},{y})\", \"image\":input_image}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoFV1kD6hrXI"
      },
      "source": [
        "### Test\n",
        "First, import `in_colab` since you only want to run this test in colab. YHat will use this colab in a callable API, so you don't want your test to run every time `predict` is called. Next, import `inference_test` which is a function to make sure your `predict` will run with YHat.\n",
        "\n",
        "Now, inside a `in_colab` boolean, first get whatever test data you'll need, in this case, an image. Then you'll call your predict function, wrapped inside  `inference_test`, passing in the same params you defined above. If something is missing, you should see an informative error. Otherwise, you'll see something like\n",
        "`Please take a look and verify the results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhNKiYae4WL1"
      },
      "outputs": [],
      "source": [
        "from yhat_params.yhat_tools import in_colab, inference_test\n",
        "\n",
        "if in_colab():\n",
        "    import urllib.request\n",
        "    from PIL import Image\n",
        "    urllib.request.urlretrieve(\"https://c4.wallpaperflare.com/wallpaper/96/207/799/look-face-pose-background-wallpaper-preview.jpg\", \"input_image.jpg\")\n",
        "    img = Image.open(\"input_image.jpg\")\n",
        "    inference_test(predict_func=predict, params={'image': img})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr0wnsJc4XJA"
      },
      "source": [
        "### That's it\n",
        "\n",
        "If you run into errors, feel free to hop into Discord.\n",
        "\n",
        "Otherwise, you'll now want to clear your outputs and save a public repo on Github"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO8/yL82SYUdzaere5gTqR7",
      "include_colab_link": true,
      "name": "lesson6_regression",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
