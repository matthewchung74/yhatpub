{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson6_multicat",
      "provenance": [],
      "authorship_tag": "ABX9TyPmOTPYhZ+P8znv9adwtp03",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yhatpub/yhatpub/blob/notebook/notebooks/fastai/lesson6_multicat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brjCYxrw34vF"
      },
      "source": [
        "# Fastai Lesson 6 Multicat on YHat.pub\n",
        "\n",
        "This notebook picks up from [Fastai Fastbook 6 multicat](https://github.com/fastai/fastbook/blob/master/06_multicat.ipynb) X to [YHat.pub](https://yhat.pub)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGehttOd6g-I"
      },
      "source": [
        "### Installs\n",
        "The following cell installs pytorch, fastai and yhat_params, which is used to decorate your `predict` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eckIQIo39vS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b465736-6af4-4197-b851-cffc16fb5f76"
      },
      "source": [
        "!pip install -q --upgrade --no-cache-dir torch torchvision torchaudio\n",
        "!pip install -q --upgrade --no-cache-dir fastai\n",
        "\n",
        "!pip install -q --no-cache-dir git+https://github.com/yhatpub/yhat_params.git@main"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 831.4 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 22.1 MB 1.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 67.0 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.9.1 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 186 kB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 50.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 62 kB 3.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 131 kB 5.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 40.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 44.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 23.6 MB/s \n",
            "\u001b[?25h  Building wheel for yhat-params (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.9.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXbb-xMt4F10"
      },
      "source": [
        "### Imports\n",
        "**Warning** don't place `pip installs` and `imports` in the same cell. The imports might not work correctly if done that way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEou7Z444C0K"
      },
      "source": [
        "from fastai.vision.all import *\n",
        "from yhat_params.yhat_tools import FieldType, inference_predict"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8T-fAxr4HCO"
      },
      "source": [
        "### Download Model\n",
        "Google drive does not allow direct downloads for files over 100MB, so you'll need to follow the snippet below to get the download url."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdBGoC__4GXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a93357-ce78-4593-a5cc-1bcb3b913e41"
      },
      "source": [
        "#file copied from google drive\n",
        "google_drive_url = \"https://drive.google.com/file/d/1eJ4SBHbxpbR6aIrx1J4Lu4bFTyL9Huj1/view?usp=sharing\"\n",
        "import os\n",
        "os.environ['GOOGLE_FILE_ID'] = google_drive_url.split('/')[5]\n",
        "os.environ['GDRIVE_URL'] = f'https://docs.google.com/uc?export=download&id={os.environ[\"GOOGLE_FILE_ID\"]}'\n",
        "!echo \"This is the Google drive download url $GDRIVE_URL\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the Google drive download url https://docs.google.com/uc?export=download&id=1eJ4SBHbxpbR6aIrx1J4Lu4bFTyL9Huj1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5zE1GY04J10"
      },
      "source": [
        "`wget` it from google drive. This script places the model in a `model` folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmoHbybY4JTy"
      },
      "source": [
        "!wget -q --no-check-certificate $GDRIVE_URL -r -A 'uc*' -e robots=off -nd\n",
        "!mkdir -p models\n",
        "!mv $(ls -S uc* | head -1) ./models/export.pth"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_l3UuJJ-OZF"
      },
      "source": [
        "Now let's do the same for the labels csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILKW4anz9mho",
        "outputId": "48ac48e9-0c50-4eb1-80bf-440898ca74af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#cleanup from previous download\n",
        "!rm uc*\n",
        "#file copied from google drive\n",
        "google_drive_url = \"https://drive.google.com/file/d/1p6gRb0v8jaBiDSGRKsYPpdnEi4IaJrcw/view?usp=sharing\"\n",
        "import os\n",
        "os.environ['GOOGLE_FILE_ID'] = google_drive_url.split('/')[5]\n",
        "os.environ['GDRIVE_URL'] = f'https://docs.google.com/uc?export=download&id={os.environ[\"GOOGLE_FILE_ID\"]}'\n",
        "!echo \"This is the Google drive download url $GDRIVE_URL\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the Google drive download url https://docs.google.com/uc?export=download&id=1p6gRb0v8jaBiDSGRKsYPpdnEi4IaJrcw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBB1cCqC9mpX"
      },
      "source": [
        "!wget -q --no-check-certificate $GDRIVE_URL -r -A 'uc*' -e robots=off -nd\n",
        "!mkdir -p models\n",
        "!mv $(ls -S uc* | head -1) ./models/vocab.csv"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJO6xPA14OJY"
      },
      "source": [
        "verify the model exists. **Warning** YHat is pretty finicky about where you place your models. Make sure you create a `model` directory and download your model(s) there  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0z3ZMaU4MQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed2a6e5-6514-477f-fc49-b8db45d7263a"
      },
      "source": [
        "!ls -l ./models"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 137304\n",
            "-rw-r--r-- 1 root root 140592177 Oct 19 00:33 export.pth\n",
            "-rw-r--r-- 1 root root      3289 Oct 19 00:33 vocab.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVunROXh6srM"
      },
      "source": [
        "**Warning** if your model depends on extra functions, as lesson6 does, you'll need to include those functions. In python, functions are not included in the exported `pkl` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGMgLBw94OqR",
        "outputId": "13d16e94-d050-47fb-b18b-db439bbfc73c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "import csv\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "with open(\"models/vocab.csv\") as file_name:\n",
        "    file_read = csv.reader(file_name)\n",
        "    labels = list(file_read)\n",
        "\n",
        "\n",
        "new_image = Image.new(mode=\"RGB\", size=(1,1))\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "new_image.save('data/dummyimage.jpg')\n",
        "\n",
        "dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
        "                   get_x=ColReader('images'), \n",
        "                   get_y=ColReader('labels'),\n",
        "                   item_tfms=Resize(192),\n",
        "                   batch_tfms=Normalize.from_stats(*imagenet_stats))\n",
        "\n",
        "df = pd.DataFrame(\n",
        "     {\n",
        "        'images': [\n",
        "                  'data/dummyimage.jpg', \n",
        "                  ]*20, \n",
        "        'labels': labels*2, \n",
        "        'valid': [True] *20\n",
        "     },\n",
        "    )\n",
        "dls = dblock.dataloaders(df, bs=64, num_workers=workers)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-ffa7602df32f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/vocab.csv\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mfile_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_read\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/vocab.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vqJRIAnBxHm",
        "outputId": "d3679723-faf0-4444-c4a7-88ed45c88327",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!less models/vocab.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b7\u001b[?47h\u001b[?1h\u001b=\r<!DOCTYPE html><html><head><title>Google Drive - Virus scan warning</title><meta \b http-equiv=\"content-type\" content=\"text/html; charset=utf-8\"/><link href=&#47;s \btatic&#47;doclist&#47;client&#47;css&#47;3735517439&#45;untrustedcontent.css rel \b=\"stylesheet\" nonce=\"VpfBzpmY+zXPQsm7nj0f1g\"><link rel=\"icon\" href=\"//ssl.gstati \bc.com/images/branding/product/1x/drive_2020q4_32dp.png\"/><style nonce=\"VpfBzpmY+ \bzXPQsm7nj0f1g\">#gbar,#guser{font-size:13px;padding-top:0px !important;}#gbar{hei \bght:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border- \btop:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;wid \bth:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{f \bloat:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#0 \b0c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important \b}\r\n",
            "</style><script nonce=\"47yaYAnWysmDyOS0u92K/g\"></script></head><body><div id=gba \br><nobr><a target=_blank class=gb1 href=\"https://www.google.com.tw/webhp?tab=ow\" \b>Search</a> <a target=_blank class=gb1 href=\"http://www.google.com.tw/imghp?hl=e \bn&tab=oi\">Images</a> <a target=_blank class=gb1 href=\"https://maps.google.com.tw \b/maps?hl=en&tab=ol\">Maps</a> <a target=_blank class=gb1 href=\"https://play.googl \be.com/?hl=en&tab=o8\">Play</a> <a target=_blank class=gb1 href=\"https://www.youtu \bbe.com/?gl=TW&tab=o1\">YouTube</a> <a target=_blank class=gb1 href=\"https://news. \bgoogle.com/?tab=on\">News</a> <a target=_blank class=gb1 href=\"https://mail.googl \be.com/mail/?tab=om\">Gmail</a> <b class=gb1>Drive</b> <a target=_blank class=gb1  \bstyle=\"text-decoration:none\" href=\"https://www.google.com.tw/intl/en/about/produ \bcts?tab=oh\"><u>More</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr>< \b\u001b[7mmodels/vocab.csv\u001b[m\u001b[K"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPKXMFUA4PI8"
      },
      "source": [
        "### Load your learner\n",
        "The following is the equivalent of torch `torch.load` or ts `model.load_weights`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLuCPtyfYQbv"
      },
      "source": [
        "learn_inf = cnn_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNrE5LX0-uIo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "50d7951d-ac49-4f82-eae3-3971436762f5"
      },
      "source": [
        "learn_inf.load('')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/env/python\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn_inf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, file, device, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin_path_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(file, model, opt, with_opt, device, strict)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mhasopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opt'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasopt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esdZzhONJBlk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff354764-fa77-44b6-d40b-6b3dc91936cb"
      },
      "source": [
        "!ls -ls models/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 300740\n",
            "300740 -rw-r--r-- 1 root root 307950809 Oct 15 22:57 export.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqYswEaoJAJs"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH1jZtMT3cfw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "f265c66a-67d9-455b-9d23-f1e90bfa56ec"
      },
      "source": [
        "    res = torch.load('models/export.pth', map_location='cpu' , pickle_module=pickle)\n",
        "    if hasattr(res, 'to_fp32'): \n",
        "        res = res.to_fp32()\n",
        "        print(\"!\")\n",
        "    if True: \n",
        "        res.dls.cpu()\n",
        "        print(\"##\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/env/python\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"##\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'dls'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ8WiWaf4Sz2"
      },
      "source": [
        "And write your predict function. Note, you will need to decorate your function with <a href=\"https://github.com/yhatpub/yhat_params\">inference_predict</a> which takes 2 parameters, a `dic` for input and output.\n",
        "\n",
        "**Info** These parameters are how YHat.pub maps your predict functions input/output of the web interface. The `dic` key is how you access the variable and the value is it's type. You can use autocomplete to see all the input/output types and more documentation on `inference_predict` is available at the link. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm0ji7TG4TLD"
      },
      "source": [
        "input = {\"image\": FieldType.PIL}\n",
        "output = {\"text\": FieldType.Text}\n",
        "\n",
        "@inference_predict(input=input, output=output)\n",
        "def predict(params):\n",
        "    img = PILImage.create(np.array(params[\"image\"].convert(\"RGB\")))\n",
        "    result = learn_inf.predict(img)\n",
        "    return {\"text\": str(result[0])}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tjb1Hac4V1L"
      },
      "source": [
        "### Test\n",
        "First, import `in_colab` since you only want to run this test in colab. YHat will use this colab in a callable API, so you don't want your test to run every time `predict` is called. Next, import `inference_test` which is a function to make sure your `predict` will run with YHat.\n",
        "\n",
        "Now, inside a `in_colab` boolean, first get whatever test data you'll need, in this case, an image. Then you'll call your predict function, wrapped inside  `inference_test`, passing in the same params you defined above. If something is missing, you should see an informative error. Otherwise, you'll see something like\n",
        "`Please take a look and verify the results`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhNKiYae4WL1"
      },
      "source": [
        "from yhat_params.yhat_tools import in_colab, inference_test\n",
        "\n",
        "if in_colab():\n",
        "    import urllib.request\n",
        "    from PIL import Image\n",
        "    urllib.request.urlretrieve(\"https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/11234019/Bulldog-standing-in-the-grass.jpg\", \"input_image.jpg\")\n",
        "    img = Image.open(\"input_image.jpg\")\n",
        "    inference_test(predict_func=predict, params={'image': img})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr0wnsJc4XJA"
      },
      "source": [
        "### That's it\n",
        "\n",
        "If you run into errors, feel free to hop into Discord.\n",
        "\n",
        "Otherwise, you'll now want to clear your outputs and save a public repo on Github"
      ]
    }
  ]
}