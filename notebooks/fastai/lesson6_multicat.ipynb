{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson6_multicat",
      "provenance": [],
      "authorship_tag": "ABX9TyOj/YjLlQ9Z4ZVkT4L2khjC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yhatpub/yhatpub/blob/notebook/notebooks/fastai/lesson6_multicat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brjCYxrw34vF"
      },
      "source": [
        "# Fastai Lesson X on YHat.pub\n",
        "\n",
        "This notebook picks up from [Fastai Fastbook X](X) X to [YHat.pub](https://yhat.pub)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGehttOd6g-I"
      },
      "source": [
        "### Installs\n",
        "The following cell installs pytorch, fastai and yhat_params, which is used to decorate your `predict` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eckIQIo39vS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f0e1507-27b4-4844-898b-3a5117c13ba8"
      },
      "source": [
        "!pip install -q --upgrade --no-cache-dir torch torchvision torchaudio\n",
        "!pip install -q --upgrade --no-cache-dir fastai\n",
        "\n",
        "!pip install -q --no-cache-dir git+https://github.com/yhatpub/yhat_params.git@main"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 831.4 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 22.1 MB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 50.0 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.9.1 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 186 kB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 63.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 131 kB 6.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 36.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 62.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 64.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 75.1 MB/s \n",
            "\u001b[?25h  Building wheel for yhat-params (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.9.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXbb-xMt4F10"
      },
      "source": [
        "### Imports\n",
        "**Warning** don't place `pip installs` and `imports` in the same cell. The imports might not work correctly if done that way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEou7Z444C0K"
      },
      "source": [
        "from fastai.vision.all import *\n",
        "from yhat_params.yhat_tools import FieldType, inference_predict"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8T-fAxr4HCO"
      },
      "source": [
        "### Download Model\n",
        "Google drive does not allow direct downloads for files over 100MB, so you'll need to follow the snippet below to get the download url."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdBGoC__4GXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e125e1-83ac-4f10-ef9f-b7905521814e"
      },
      "source": [
        "#file copied from google drive\n",
        "google_drive_url = \"https://drive.google.com/file/d/13YkQ-mSp7H7qh0CRrVskWxAOozRb0dTE/view?usp=sharing\"\n",
        "import os\n",
        "os.environ['GOOGLE_FILE_ID'] = google_drive_url.split('/')[5]\n",
        "os.environ['GDRIVE_URL'] = f'https://docs.google.com/uc?export=download&id={os.environ[\"GOOGLE_FILE_ID\"]}'\n",
        "!echo \"This is the Google drive download url $GDRIVE_URL\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the Google drive download url https://docs.google.com/uc?export=download&id=13YkQ-mSp7H7qh0CRrVskWxAOozRb0dTE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5zE1GY04J10"
      },
      "source": [
        "`wget` it from google drive. This script places the model in a `model` folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmoHbybY4JTy"
      },
      "source": [
        "!wget -q --no-check-certificate $GDRIVE_URL -r -A 'uc*' -e robots=off -nd\n",
        "!mkdir -p model\n",
        "!mv $(ls -S uc* | head -1) ./model/export.pkl"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJO6xPA14OJY"
      },
      "source": [
        "verify the model exists. **Warning** YHat is pretty finicky about where you place your models. Make sure you create a `model` directory and download your model(s) there  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0z3ZMaU4MQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0589dcdb-3353-4228-e3c4-b8eeb4a981ea"
      },
      "source": [
        "!ls -l ./model/export.pkl"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 102978527 Oct 15 17:04 ./model/export.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVunROXh6srM"
      },
      "source": [
        "**Warning** if your model depends on extra functions, as lesson6 does, you'll need to include those functions. In python, functions are not included in the exported `pkl` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGMgLBw94OqR"
      },
      "source": [
        "def get_x(r): return r['fname']\n",
        "def get_y(r): return r['labels']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPKXMFUA4PI8"
      },
      "source": [
        "### Load your learner\n",
        "The following is the equivalent of torch `torch.load` or ts `model.load_weights`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_JXmfFg4ROO"
      },
      "source": [
        "learn_inf = load_learner('./model/export.pkl')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ8WiWaf4Sz2"
      },
      "source": [
        "And write your predict function. Note, you will need to decorate your function with <a href=\"https://github.com/yhatpub/yhat_params\">inference_predict</a> which takes 2 parameters, a `dic` for input and output.\n",
        "\n",
        "**Info** These parameters are how YHat.pub maps your predict functions input/output of the web interface. The `dic` key is how you access the variable and the value is it's type. You can use autocomplete to see all the input/output types and more documentation on `inference_predict` is available at the link. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm0ji7TG4TLD"
      },
      "source": [
        "input = {\"image\": FieldType.PIL}\n",
        "output = {\"text\": FieldType.Text}\n",
        "\n",
        "@inference_predict(input=input, output=output)\n",
        "def predict(params):\n",
        "    img = PILImage.create(np.array(params[\"image\"].convert(\"RGB\")))\n",
        "    result = learn_inf.predict(img)\n",
        "    return {\"text\": str(result[0])}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tjb1Hac4V1L"
      },
      "source": [
        "### Test\n",
        "First, import `in_colab` since you only want to run this test in colab. YHat will use this colab in a callable API, so you don't want your test to run every time `predict` is called. Next, import `inference_test` which is a function to make sure your `predict` will run with YHat.\n",
        "\n",
        "Now, inside a `in_colab` boolean, first get whatever test data you'll need, in this case, an image. Then you'll call your predict function, wrapped inside  `inference_test`, passing in the same params you defined above. If something is missing, you should see an informative error. Otherwise, you'll see something like\n",
        "`Please take a look and verify the results`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhNKiYae4WL1",
        "outputId": "e91ce337-9333-4956-d7a3-29d3fe41f9ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "from yhat_params.yhat_tools import in_colab, inference_test\n",
        "\n",
        "if in_colab():\n",
        "    import urllib.request\n",
        "    from PIL import Image\n",
        "    urllib.request.urlretrieve(\"https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/11234019/Bulldog-standing-in-the-grass.jpg\", \"input_image.jpg\")\n",
        "    img = Image.open(\"input_image.jpg\")\n",
        "    inference_test(predict_func=predict, params={'image': img})"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['dog'], tensor([False, False, False, False, False, False, False, False, False, False,\n",
            "        False,  True, False, False, False, False, False, False, False, False]), tensor([1.2632e-04, 4.5536e-03, 2.2570e-03, 4.7902e-03, 1.1473e-02, 4.1468e-04,\n",
            "        4.1871e-03, 3.6704e-04, 3.9516e-03, 3.0914e-04, 4.4232e-03, 9.9674e-01,\n",
            "        1.4760e-03, 2.9708e-04, 1.8034e-02, 2.7210e-03, 2.1427e-03, 6.6613e-03,\n",
            "        2.2153e-03, 3.7065e-03]))\n",
            "Wrote results to result.json duration: 0.140002 seconds\n",
            "Please take a look and verify the results\n",
            "{\n",
            "    \"text\": \"['dog']\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr0wnsJc4XJA"
      },
      "source": [
        "### That's it\n",
        "\n",
        "If you run into errors, feel free to hop into Discord.\n",
        "\n",
        "Otherwise, you'll now want to clear your outputs and save a public repo on Github"
      ]
    }
  ]
}