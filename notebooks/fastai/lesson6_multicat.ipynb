{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson6_multicat",
      "provenance": [],
      "authorship_tag": "ABX9TyMPoNSlZpSSSf+UhD8DO37d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yhatpub/yhatpub/blob/notebook/notebooks/fastai/lesson6_multicat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brjCYxrw34vF"
      },
      "source": [
        "# Fastai Lesson 6 Multicat on YHat.pub\n",
        "\n",
        "This notebook picks up from [Fastai Fastbook 6 multicat](https://github.com/fastai/fastbook/blob/master/06_multicat.ipynb) X to [YHat.pub](https://yhat.pub)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGehttOd6g-I"
      },
      "source": [
        "### Installs\n",
        "The following cell installs pytorch, fastai and yhat_params, which is used to decorate your `predict` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eckIQIo39vS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a518a90a-62f3-4c84-8941-6c5caece50dd"
      },
      "source": [
        "!pip install -q --upgrade --no-cache-dir torch torchvision torchaudio\n",
        "!pip install -q --upgrade --no-cache-dir fastai\n",
        "\n",
        "!pip install -q --no-cache-dir git+https://github.com/yhatpub/yhat_params.git@main"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXbb-xMt4F10"
      },
      "source": [
        "### Imports\n",
        "**Warning** don't place `pip installs` and `imports` in the same cell. The imports might not work correctly if done that way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEou7Z444C0K"
      },
      "source": [
        "from fastai.vision.all import *\n",
        "from yhat_params.yhat_tools import FieldType, inference_predict"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8T-fAxr4HCO"
      },
      "source": [
        "### Download Model\n",
        "Google drive does not allow direct downloads for files over 100MB, so you'll need to follow the snippet below to get the download url."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdBGoC__4GXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc3a9355-ade5-4b4c-f639-e11c30332b5b"
      },
      "source": [
        "#file copied from google drive\n",
        "google_drive_url = \"https://drive.google.com/file/d/1eJ4SBHbxpbR6aIrx1J4Lu4bFTyL9Huj1/view?usp=sharing\"\n",
        "import os\n",
        "os.environ['GOOGLE_FILE_ID'] = google_drive_url.split('/')[5]\n",
        "os.environ['GDRIVE_URL'] = f'https://docs.google.com/uc?export=download&id={os.environ[\"GOOGLE_FILE_ID\"]}'\n",
        "!echo \"This is the Google drive download url $GDRIVE_URL\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the Google drive download url https://docs.google.com/uc?export=download&id=1eJ4SBHbxpbR6aIrx1J4Lu4bFTyL9Huj1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5zE1GY04J10"
      },
      "source": [
        "`wget` it from google drive. This script places the model in a `model` folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmoHbybY4JTy"
      },
      "source": [
        "!wget -q --no-check-certificate $GDRIVE_URL -r -A 'uc*' -e robots=off -nd\n",
        "!mkdir -p models\n",
        "!mv $(ls -S uc* | head -1) ./models/export.pth"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_l3UuJJ-OZF"
      },
      "source": [
        "Now let's do the same for the labels csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILKW4anz9mho"
      },
      "source": [
        "#cleanup from previous download\n",
        "!rm uc*\n",
        "#file copied from google drive\n",
        "google_drive_url = \"https://drive.google.com/file/d/1p6gRb0v8jaBiDSGRKsYPpdnEi4IaJrcw/view?usp=sharing\"\n",
        "import os\n",
        "os.environ['GOOGLE_FILE_ID'] = google_drive_url.split('/')[5]\n",
        "os.environ['GDRIVE_URL'] = f'https://docs.google.com/uc?export=download&id={os.environ[\"GOOGLE_FILE_ID\"]}'\n",
        "!echo \"This is the Google drive download url $GDRIVE_URL\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBB1cCqC9mpX"
      },
      "source": [
        "!wget -q --no-check-certificate $GDRIVE_URL -r -A 'uc*' -e robots=off -nd\n",
        "!mkdir -p models\n",
        "!mv $(ls -S uc* | head -1) ./models/vocab.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJO6xPA14OJY"
      },
      "source": [
        "verify the model exists. **Warning** YHat is pretty finicky about where you place your models. Make sure you create a `model` directory and download your model(s) there  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0z3ZMaU4MQ8"
      },
      "source": [
        "!ls -l ./models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVunROXh6srM"
      },
      "source": [
        "**Warning** if your model depends on extra functions, as lesson6 does, you'll need to include those functions. In python, functions are not included in the exported `pkl` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4VxAeNJy4gL"
      },
      "source": [
        "!less models/vocab.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGMgLBw94OqR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "b2bf3105-d6ca-4627-a5d0-e11bfd9b12de"
      },
      "source": [
        "import csv\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "with open(\"models/vocab.csv\") as file_name:\n",
        "    file_read = csv.reader(file_name)\n",
        "    labels = list(file_read)\n",
        "\n",
        "new_image = Image.new(mode=\"RGB\", size=(1,1))\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "new_image.save('data/dummyimage.jpg')\n",
        "\n",
        "dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
        "                   get_x=ColReader('images'), \n",
        "                   get_y=ColReader('labels'),\n",
        "                   item_tfms=Resize(192),\n",
        "                   batch_tfms=Normalize.from_stats(*imagenet_stats))\n",
        "\n",
        "df = pd.DataFrame(\n",
        "     {\n",
        "        'images': [\n",
        "                  'data/dummyimage.jpg', \n",
        "                  ]*20, \n",
        "        'labels': labels*2, \n",
        "        'valid': [True] *20\n",
        "     },\n",
        "    )\n",
        "dls = dblock.dataloaders(df, bs=64, num_workers=workers)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ccbe4f8f013e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                   ]*20, \n\u001b[1;32m     25\u001b[0m         \u001b[0;34m'labels'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;34m'valid'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m      },\n\u001b[1;32m     28\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vqJRIAnBxHm",
        "outputId": "e0f1a20b-9afb-4de7-f8c1-90fc95167875"
      },
      "source": [
        "!less models/vocab.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b7\u001b[?47h\u001b[?1h\u001b=\r0\r\n",
            "aeroplane\r\n",
            "bicycle\r\n",
            "bird\r\n",
            "boat\r\n",
            "bottle\r\n",
            "bus\r\n",
            "car\r\n",
            "cat\r\n",
            "chair\r\n",
            "cow\r\n",
            "diningtable\r\n",
            "dog\r\n",
            "horse\r\n",
            "motorbike\r\n",
            "person\r\n",
            "pottedplant\r\n",
            "sheep\r\n",
            "sofa\r\n",
            "train\r\n",
            "tvmonitor\r\n",
            "\u001b[7mmodels/vocab.csv (END)\u001b[m\u001b[K"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPKXMFUA4PI8"
      },
      "source": [
        "### Load your learner\n",
        "The following is the equivalent of torch `torch.load` or ts `model.load_weights`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLuCPtyfYQbv"
      },
      "source": [
        "learn_inf = cnn_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNrE5LX0-uIo"
      },
      "source": [
        "learn_inf.load('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esdZzhONJBlk"
      },
      "source": [
        "!ls -ls models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqYswEaoJAJs"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH1jZtMT3cfw"
      },
      "source": [
        "    res = torch.load('models/export.pth', map_location='cpu' , pickle_module=pickle)\n",
        "    if hasattr(res, 'to_fp32'): \n",
        "        res = res.to_fp32()\n",
        "        print(\"!\")\n",
        "    if True: \n",
        "        res.dls.cpu()\n",
        "        print(\"##\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ8WiWaf4Sz2"
      },
      "source": [
        "And write your predict function. Note, you will need to decorate your function with <a href=\"https://github.com/yhatpub/yhat_params\">inference_predict</a> which takes 2 parameters, a `dic` for input and output.\n",
        "\n",
        "**Info** These parameters are how YHat.pub maps your predict functions input/output of the web interface. The `dic` key is how you access the variable and the value is it's type. You can use autocomplete to see all the input/output types and more documentation on `inference_predict` is available at the link. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm0ji7TG4TLD"
      },
      "source": [
        "input = {\"image\": FieldType.PIL}\n",
        "output = {\"text\": FieldType.Text}\n",
        "\n",
        "@inference_predict(input=input, output=output)\n",
        "def predict(params):\n",
        "    img = PILImage.create(np.array(params[\"image\"].convert(\"RGB\")))\n",
        "    result = learn_inf.predict(img)\n",
        "    return {\"text\": str(result[0])}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tjb1Hac4V1L"
      },
      "source": [
        "### Test\n",
        "First, import `in_colab` since you only want to run this test in colab. YHat will use this colab in a callable API, so you don't want your test to run every time `predict` is called. Next, import `inference_test` which is a function to make sure your `predict` will run with YHat.\n",
        "\n",
        "Now, inside a `in_colab` boolean, first get whatever test data you'll need, in this case, an image. Then you'll call your predict function, wrapped inside  `inference_test`, passing in the same params you defined above. If something is missing, you should see an informative error. Otherwise, you'll see something like\n",
        "`Please take a look and verify the results`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhNKiYae4WL1"
      },
      "source": [
        "from yhat_params.yhat_tools import in_colab, inference_test\n",
        "\n",
        "if in_colab():\n",
        "    import urllib.request\n",
        "    from PIL import Image\n",
        "    urllib.request.urlretrieve(\"https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/11234019/Bulldog-standing-in-the-grass.jpg\", \"input_image.jpg\")\n",
        "    img = Image.open(\"input_image.jpg\")\n",
        "    inference_test(predict_func=predict, params={'image': img})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr0wnsJc4XJA"
      },
      "source": [
        "### That's it\n",
        "\n",
        "If you run into errors, feel free to hop into Discord.\n",
        "\n",
        "Otherwise, you'll now want to clear your outputs and save a public repo on Github"
      ]
    }
  ]
}