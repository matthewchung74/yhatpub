{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fastai_template.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNpR7islCHsatCX0DzwY3WG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yhatpub/yhatpub/blob/notebook/notebooks/fastai/lesson10_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brjCYxrw34vF"
      },
      "source": [
        "# Fastai Lesson 10 on YHat.pub\n",
        "\n",
        "This notebook picks up from [Fastai Fastbook 10 Text Classification](https://github.com/yhatpub/blogs/blob/main/10_nlp.ipynb) to [YHat.pub](https://yhat.pub)\n",
        "\n",
        "To save your model, you'll need to export the pickled model after training. Here is an example below\n",
        "```\n",
        "learn.export('/content/export.pkl')\n",
        "from google.colab import files\n",
        "files.download('/content/export.pkl')\n",
        "```\n",
        "Then upload it for public accessibility. Here is an example using [Google Drive](https://github.com/yhatpub/yhatpub#step-2-upload-your-model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0poAZ683-11"
      },
      "source": [
        "### Installs\n",
        "The following cell installs pytorch, fastai and yhat_params, which is used to decorate your `predict` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEou7Z444C0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c93fb13-6847-4406-d62f-b2bccb14b849"
      },
      "source": [
        "!pip install -q --upgrade --no-cache-dir torch\n",
        "!pip install -q --upgrade --no-cache-dir fastai\n",
        "\n",
        "!pip install -q --no-cache-dir git+https://github.com/yhatpub/yhat_params.git@main"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 881.9 MB 1.2 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu111 requires torch==1.9.0, but you have torch 1.10.0 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 189 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 51.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 1.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 131 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 22.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 18.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 68.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 50.9 MB/s \n",
            "\u001b[?25h  Building wheel for yhat-params (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXbb-xMt4F10"
      },
      "source": [
        "### Imports\n",
        "**Warning** don't place `pip installs` and `imports` in the same cell. The imports might not work correctly if done that way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdBGoC__4GXd"
      },
      "source": [
        "from fastai.text.all import *\n",
        "from yhat_params.yhat_tools import FieldType, inference_predict"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8T-fAxr4HCO"
      },
      "source": [
        "### Download Model\n",
        "Google drive does not allow direct downloads for files over 100MB, so you'll need to follow the snippet below to get the download url."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmoHbybY4JTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f14ab28-2456-4f6b-d670-f778e63dfa44"
      },
      "source": [
        "#cleanup from previous download\n",
        "!rm -f uc*\n",
        "\n",
        "#file copied from google drive\n",
        "google_drive_url = \"https://drive.google.com/file/d/1rs1lYSiVBOG_ZMso2mvIMZaWCQxcDikx/view?usp=sharing\"\n",
        "import os\n",
        "os.environ['GOOGLE_FILE_ID'] = google_drive_url.split('/')[5]\n",
        "os.environ['GDRIVE_URL'] = f'https://docs.google.com/uc?export=download&id={os.environ[\"GOOGLE_FILE_ID\"]}'\n",
        "!echo \"This is the Google drive download url $GDRIVE_URL\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the Google drive download url https://docs.google.com/uc?export=download&id=1rs1lYSiVBOG_ZMso2mvIMZaWCQxcDikx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5zE1GY04J10"
      },
      "source": [
        "`wget` it from google drive. This script places the model in a `model` folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0z3ZMaU4MQ8"
      },
      "source": [
        "!wget -q --no-check-certificate $GDRIVE_URL -r -A 'uc*' -e robots=off -nd\n",
        "!mkdir -p models\n",
        "!mv $(ls -S uc* | head -1) ./models/export.pkl"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJO6xPA14OJY"
      },
      "source": [
        "verify the model exists. **Warning** YHat is pretty finicky about where you place your models. Make sure you create a `model` directory and download your model(s) there  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGMgLBw94OqR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff13c391-968d-47e1-894c-88cab86136c8"
      },
      "source": [
        "!ls -l models"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 228216\n",
            "-rw-r--r-- 1 root root 233693037 Oct 26 00:49 export.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPKXMFUA4PI8"
      },
      "source": [
        "### Load your learner\n",
        "The following is the equivalent of torch `torch.load` or ts `model.load_weights`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_JXmfFg4ROO"
      },
      "source": [
        "learn_inf = load_learner('models/export.pkl')\n",
        "learn_inf.model.eval();"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ8WiWaf4Sz2"
      },
      "source": [
        "And write your predict function. Note, you will need to decorate your function with <a href=\"https://github.com/yhatpub/yhat_params\">inference_predict</a> which takes 2 parameters, a `dic` for input and output.\n",
        "\n",
        "**Info** These parameters are how YHat.pub maps your predict functions input/output of the web interface. The `dic` key is how you access the variable and the value is it's type. You can use autocomplete to see all the input/output types and more documentation on `inference_predict` is available at the link. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm0ji7TG4TLD"
      },
      "source": [
        "input = {\"text\": FieldType.Text}\n",
        "output = {\"text\": FieldType.Text}\n",
        "\n",
        "@inference_predict(input=input, output=output)\n",
        "def predict(params):\n",
        "    preds = learn_inf.predict(params[\"text\"]) \n",
        "    return {\"text\": str(preds)}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tjb1Hac4V1L"
      },
      "source": [
        "### Test\n",
        "First, import `in_colab` since you only want to run this test in colab. YHat will use this colab in a callable API, so you don't want your test to run every time `predict` is called. Next, import `inference_test` which is a function to make sure your `predict` will run with YHat.\n",
        "\n",
        "Now, inside a `in_colab` boolean, first get whatever test data you'll need, in this case, an image. Then you'll call your predict function, wrapped inside  `inference_test`, passing in the same params you defined above. If something is missing, you should see an informative error. Otherwise, you'll see something like\n",
        "`Please take a look and verify the results`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhNKiYae4WL1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b59ef3e4-1cee-41e0-fec8-fcdfc1d3dbef"
      },
      "source": [
        "from yhat_params.yhat_tools import in_colab, inference_test\n",
        "\n",
        "if in_colab():\n",
        "    inference_test(predict_func=predict, params={'text': \"I liked this movie\"})"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote results to result.json duration: 0.135092 seconds\n",
            "Please take a look and verify the results\n",
            "{\n",
            "    \"text\": \"('pos', tensor(1), tensor([3.2649e-04, 9.9967e-01]))\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr0wnsJc4XJA"
      },
      "source": [
        "### That's it\n",
        "\n",
        "If you run into errors, feel free to hop into Discord.\n",
        "\n",
        "Otherwise, you'll now want to clear your outputs and save a public repo on Github"
      ]
    }
  ]
}